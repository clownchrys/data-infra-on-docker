name: "onnx_backend"
platform: "onnxruntime_onnx"
backend: "onnxruntime"
runtime: ""

version_policy: {
    latest: { num_versions: 2 }
    #all: {}
    #specific: { versions: [1, 2] }
}

input: [
    {
        name: "INPUT_01",
        data_type: TYPE_INT32,
        format: FORMAT_NONE,
        dims: [ 1 ],
        is_shape_tensor: false,
        allow_ragged_batch: false,
        optional: false
    },
    {
        name: "INPUT_02",
        data_type: TYPE_INT32,
        format: FORMAT_NONE,
        dims: [ 1 ],
        is_shape_tensor: false,
        allow_ragged_batch: false,
        optional: false
    }
]
output: [
    {
        name: "OUTPUT_01",
        data_type: TYPE_FP32,
        dims: [ 1 ],
        label_filename: "",
        is_shape_tensor: false
    }
]
batch_input: []
batch_output: []
max_batch_size: 0

optimization: {
    priority: PRIORITY_DEFAULT,
    input_pinned_memory: { enable: true },
    output_pinned_memory: { enable: true },
    gather_kernel_buffer_threshold: 0,
    eager_batching: false
}

instance_group: [
    {
        name: "MODEL-INSTANCE-GROUP-CPU-01",
        kind: KIND_CPU,
        count: 1,
        gpus: [],
        secondary_devices: [],
        profile: [],
        passive: false,
        host_policy: ""
    }
]

default_model_filename: "model.onnx",
cc_model_filenames: {},
metric_tags: {},
parameters: {},
model_warmup: []
